<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="HuDOR: Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards">
  <meta name="keywords" content="Reinforcement Learning, Robot Hand manipulation, Robot Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HuDOR: Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <!--<script defer src="./static/js/fontawesome.all.min.js"></script>-->
  <script src="https://kit.fontawesome.com/8a0d0cac45.js" crossorigin="anonymous"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>



  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">HuDOR: Bridging the Human to Robot Dexterity Gap through
              Object-Oriented Rewards</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://irmakguzey.github.io/">Irmak Guzey</a>,</span>
              <span class="author-block">
                <a href="https://yinlongdai.github.io/">Yinlong Dai</a>,
              </span>
              <span class="author-block">
                <a href="https://georgysavva.github.io/">Georgy Savva</a>,
              </span>
              <span class="author-block">
                <a href="https://raunaqbhirangi.github.io/">Raunaq Bhirangi</a>,</span>
              <span class="author-block">
                <a href="https://www.lerrelpinto.com/">Lerrel Pinto</a>,
              </span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"> New York University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/12di1sZnlGyfX-WCCHupctXe0ffwfNBE9/view?usp=sharing" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa-solid fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/12di1sZnlGyfX-WCCHupctXe0ffwfNBE9/view?usp=sharing" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Put a new line-->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
        <!-- <div class="column"> -->
          <div class="publication-video">
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/hudor_compr_more.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <br />
      <br />

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Training robots directly from human videos is
              an emerging area in robotics and computer vision. While
              there has been notable progress with two-fingered grippers,
              learning autonomous tasks without teleoperation remains a
              difficult problem for multi-fingered robot hands. A key reason
              for this difficulty is that a policy trained on human hands
              may not directly transfer to a robot hand with a different
              morphology.
            </p>
            <p>
              In this work, we present HUDOR, a technique
              that enables online fine-tuning of the policy by constructing
              a reward function from the human video. Importantly, this
              reward function is built using object-oriented rewards derived
              from off-the-shelf point trackers, which allows for meaningful
              learning signals even when the robot hand is in the visual
              observation, while the human hand is used to construct the
              reward. Given a single video of human solving a task, such
              as gently opening a music box, HUDOR allows our four-
              fingered Allegro hand to learn this task with just an hour of
              online interaction. Our experiments across four tasks, show
              that HUDOR outperforms alternatives with an average of 4×
              improvement.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
  </section>


  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/website_method.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>


      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-centered">
            <p>
              <!-- We present <b>HuDOR</b>, a technique that enables multi-fingered robot hands to learn dexterous tasks by
              leveraging object-oriented rewards derived from human videos. By tracking the motion of objects rather
              than focusing on hand morphology, HUDOR constructs reward functions that guide the robot's learning
              process through inverse reinforcement learning. The system refines an initial robot policy by comparing
              the object’s trajectory in human and robot videos, allowing the robot to adapt and perform tasks such as
              opening a box with just an hour of online training. Unlike traditional methods, HUDOR eliminates the need
              for teleoperation or extensive human demonstrations, and it generalizes well to new objects, though its
              effectiveness decreases with significant changes in object texture or weight. -->

              <b>HuDOR</b> generates rewards from human videos by tracking points on the manipulable object, 
              indicated by the rainbow-colored dots, over the trajectory. 
              This allows for online training of multi-fingered robot hands given only a single video of a human solving the task (left) 
              and without robot teleoperation. To optimize the robot's policy (middle), 
              rewards are computed by matching the point movements of the robot policy with those in the human video. 
              In under an hour of online fine-tuning, our Allegro robot hand (right) is able to <i>open the music box</i>.
            </p>
          </div>
          <div class="content has-text-centered">
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 style="margin-bottom: 1em ;" class="title is-3">Policy Rollouts</h2>
          <div class="content">
            <p>In the videos below you can see HuDOR solve four various tasks</p>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Music Box Opening</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/music_box_comp.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Paper Sliding</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/paper_sliding_comp.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Bread Picking</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%"> 
              <source src="./static/videos/bread_picking_comp.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Card Sliding</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/card_sliding_comp.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 style="margin-bottom: 1em ;" class="title is-3">Policy Generalization</h2>
          <div class="content">
            <p>              Generalization experiments on Bread Picking and Card
              Sliding task. We input the text prompts on top and bottom as input
              to the language grounded SAM model to get the initial mask for
              each object.</p>
          </div>
        </div>
      </div>
      <h3 style="text-align: center;" class="title is-4">Bread Picking Task</h3>

      <div class="columns is-centered">

        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-4">Dobby</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/gen_dobby_comp.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-4">Brown Music Box</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/gen_music_box_comp.mp4" type="video/mp4">
            </video>
          </div>
        </div>
          <div class="column">
            <div class="content has-text-centered">
              <h4 class="title is-4">Medicine Bottle</h4>
              <video id="dollyzoom" controls muted loop playsinline height="100%">
                <source src="./static/videos/gen_medicine_comp.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-4">Red Peg</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/gen_red_peg_comp.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h3 style="text-align: center;" class="title is-4">Card Sliding Task</h3>

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-4">Gum Package</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/gen_card_gum.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-4">Small Plate</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/gen_card_plate.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-4">Brown Tissue</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/gen_card_tissue.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-4">Yellow Tea Bag</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/gen_card_tea_bag.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
  
  
      <div class="columns is-centered">
         <div class="column is-full-width">
          <h2 class="title is-3">Experiment Results</h2>
          <div class="content">
            <p> We ran experiments to answer the following two questions: 
            </p>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <!-- <h3 class="title is-4">Comparison Across Sensors -- Plug Insertion</h3> -->
            <img src="./static/images/online_experiments.png" alt="Online Experiments" />
            <p>
              We compared HuDOR to 3 different offline baselines. We ablate the input and the amount of demonstrations used to experiment on different aspects.
              <b>HuDOR</b> improves upon all of these offline baselines, showcasing the importance of online corrections for better dexterity.
            </p>
          </div>

          <!-- <div class="content">
            <img src="./static/images/website_trajectories_moving.png" alt="Trajectories Moving" />
            <p>
              We also illustrate above, how online learning improves the policy in the Paper Sliding task. 
              As can be seen, <b>HuDOR</b> enables the robot policy trajectory to move progressively closer to that of the human expert.
            </p>
          </div> -->

          

          <h3 style="text-align: center;" class="title is-4">How does the online finetuning improve the policy?</h3>
          <div class="content">
            <p>
              We also illustrate below, how online learning improves the policy in the Paper Sliding task. 
              As can be seen, <b>HuDOR</b> enables the robot policy trajectory to move progressively closer to that of the human expert.
            </p>
            <img src="./static/images/website_trajectories_moving.png" alt="Trajectories Moving" />
          </div>


        </div>
      </div>

      <h3 style="text-align: center;" class="title is-4">Rollouts of Offline Baselines</h3>
      <p>
        We show the rollouts of our best offline baseline Point Cloud BC for three of our tasks below. 
        Note how, in the Bread Picking and Paper Sliding tasks, the hand progressively lowers, 
        while in the Card Sliding task, once the card is slid to the edge, the algorithm fails to recover.
      </p>

      <br>
      
      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-size-6">Bread Picking Success</h4>
             <!-- <p></p> -->
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/point_cloud_bc_bread_picking_success.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-size-6">Bread Picking Failure</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/point_cloud_bc_bread_picking_failure.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-size-6">Card Sliding</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/point_cloud_bc_card_sliding.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h4 class="title is-size-6">Paper Sliding</h4>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/point_cloud_bc_paper_sliding.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>



      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <!-- <h3 class="title is-4">Comparison Across Sensors -- Plug Insertion</h3> -->
            <img src="./static/images/reward_experiments.png" alt="Reward Experiments" />

            <p>
              In HuDOR, we use points trajectory based reward functions to guide the online learning. 
              We ablate over our design decision, and train online policies for three of our tasks with 
              image representation based and points based reward functions. 
            </p>
            <p>
              <b>HuDOR</b> shows improvement over both of these baselines. 
            </p>

          </div>
        </div>
      </div>

      

    </div>
  </section>



  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>